{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d1d952b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "embeddings = datasets.load_from_disk(\"embeddings\")['embeddings']\n",
    "labels = datasets.load_from_disk(\"labels\")['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c49c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.transform as sktransform\n",
    "\n",
    "new_shape = (8, 8)\n",
    "def scale_image(image):\n",
    "    return sktransform.resize(image, new_shape, anti_aliasing=True)\n",
    "\n",
    "def refine_region(region):\n",
    "    region = np.array(region, dtype=np.float32)\n",
    "    if min(region.shape) / max(region.shape) < 0.1:\n",
    "        region = region[0:min(region.shape), 0:min(region.shape)]\n",
    "    if region.shape[0] > region.shape[1]:\n",
    "        region = np.pad(region, ((0, 0), (0, region.shape[0] - region.shape[1])), 'constant', constant_values=0)\n",
    "    elif region.shape[0] < region.shape[1]:\n",
    "        region = np.pad(region, ((0, region.shape[1] - region.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    region = scale_image(region)\n",
    "    region = region / region.max()\n",
    "    region = np.sqrt(2 * region - region**2)\n",
    "    region = np.round(region * 255).astype(np.uint8)\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "642446ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(64) \n",
    "\n",
    "for em in embeddings:\n",
    "    index.add(np.array(em, dtype=np.uint8))\n",
    "    \n",
    "def get_embedding(region):\n",
    "    return index.search(region, k=1)[1][0][0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "534a4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image(path):\n",
    "    return cv2.imread(path)\n",
    "\n",
    "def load_all_images(image_paths, num_workers=None):\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        images = list(tqdm(executor.map(load_image, image_paths), total=len(image_paths)))\n",
    "    return images\n",
    "\n",
    "def rgb_to_gray(im):\n",
    "    return 255 - im[:, :, 0]\n",
    "\n",
    "directory = 'D:\\\\formula_images\\\\formula_images\\\\'\n",
    "    \n",
    "def get_image(image):\n",
    "    image = rgb_to_gray(image).transpose()\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    ems = []\n",
    "    pos = []\n",
    "    for label in range(1, num_labels): \n",
    "        x, y, w, h, area = stats[label]\n",
    "        pos.append((y, x, y + h - 1, x + w - 1))\n",
    "        ems.append(get_embedding(refine_region((labels[y:y+h, x:x+w] == label).astype(np.uint8).transpose()).reshape(1, -1)))\n",
    "    return ems, pos\n",
    "\n",
    "def get_all_images(images, num_workers=None):\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        ans = list(tqdm(executor.map(get_image, images), total=len(images)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "185f286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_id[label] = i\n",
    "\n",
    "def process_formula(formula):\n",
    "    return [label_id[lb] + 1 for lb in formula.strip().split(' ')]\n",
    "\n",
    "def process_all_formulas(formulas, num_workers=None):\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        formula = list(tqdm(executor.map(process_formula, formulas), total=len(formulas)))\n",
    "    return formula\n",
    "\n",
    "max_workers = 24\n",
    "block_size = max_workers * 5\n",
    "\n",
    "def process_data(data, max_data = -1):\n",
    "    ans = []\n",
    "    if max_data == -1:\n",
    "        max_data = len(data)\n",
    "    latex_formulas = data['formula']\n",
    "    image_paths = data['image']\n",
    "    for block in range(0, max_data, block_size):\n",
    "        if block >= 1000 and block - block_size < 1000:\n",
    "            print('Processed:', block)\n",
    "        if block >= max_data:\n",
    "            break\n",
    "        images = load_all_images([directory + image_paths[i] for i in range(block, block + block_size) if i < max_data], max_workers)\n",
    "        inputs = get_all_images(images, max_workers)\n",
    "        for i in range(len(images)):\n",
    "            if type(latex_formulas[block + i]) != str:\n",
    "                continue\n",
    "            ans.append({'embeddings': inputs[i][0], 'pos': inputs[i][1], 'formula': process_formula(latex_formulas[block + i])})\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba173b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "train = process_data(pandas.read_csv('.\\\\..\\\\dataset\\\\im2latex_train.csv'))\n",
    "test = process_data(pandas.read_csv('.\\\\..\\\\dataset\\\\im2latex_test.csv'))\n",
    "validate = process_data(pandas.read_csv('.\\\\..\\\\dataset\\\\im2latex_validate.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593f72d382ce4769a959c2785547b682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e736f0f07be40c096ef97873350cd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets.Dataset.save_to_disk(\n",
    "    datasets.Dataset.from_list(train),\n",
    "    'train_dataset'\n",
    ")\n",
    "datasets.Dataset.save_to_disk(\n",
    "    datasets.Dataset.from_list(test),\n",
    "    'test_dataset'\n",
    ")\n",
    "datasets.Dataset.save_to_disk(\n",
    "    datasets.Dataset.from_list(validate),\n",
    "    'validate_dataset'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
